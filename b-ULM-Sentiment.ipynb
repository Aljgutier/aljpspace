{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL Language Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.1 Load Raw Text Corpus  \n",
    "1.2 Clean Text and Create Text Tokens  \n",
    "1.3 Numericalized Tokens  \n",
    "1.4 Pre-trained LM weights  \n",
    "1.5 Language Model and Concatenate all documents  \n",
    "1.6 Fit Language Model  \n",
    "1.7 Measuring LM performance  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1.post2\n",
      "1.15.1\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "import html\n",
    "print(torch.__version__)\n",
    "print(np.__version__)\n",
    "# torch version should be pre 1.0 for compatibility with Fastai 0.7\n",
    "# np version should be 1.15 for compatibility with Fastai 0.7\n",
    "\n",
    "%run -i ./code/sentiment_imdb_helpers.py\n",
    "\n",
    "PATH=Path('data/aclImdb/')\n",
    "\n",
    "# in NLP you will see LM (Language Model) path by convention\n",
    "LM_PATH=Path('data/imdb_lm/')\n",
    "LM_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# Clas Path and Col Names\n",
    "CLAS_PATH=Path('data/imdb_clas/')\n",
    "CLAS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "chunksize=24000\n",
    "col_names = ['labels','text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/aclImdb/train/neg\n",
      "data/aclImdb/train/pos\n",
      "data/aclImdb/train/unsup\n",
      "data/aclImdb/test/neg\n",
      "data/aclImdb/test/pos\n",
      "data/aclImdb/test/unsup\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000 75000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Awesome blend of love and suspense. A top clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Look, I loved the PROPER Anchorman film, but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Set in World Depression Era Prague, this is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt; Praise is the only thing I can gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>There's a general rule to follow about Bogart ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0       2  Awesome blend of love and suspense. A top clas...\n",
       "1       0  Look, I loved the PROPER Anchorman film, but t...\n",
       "2       1  Set in World Depression Era Prague, this is th...\n",
       "3       2  <br /><br /> Praise is the only thing I can gi...\n",
       "4       2  There's a general rule to follow about Bogart ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg\\n', 'pos\\n', 'unsup\\n']\n"
     ]
    }
   ],
   "source": [
    "# find it much easier to process text within Python, rather than helper functions\n",
    "#   processing text with Python is straight forward, not that hard\n",
    "# load, shuffle, create df, save \n",
    "\n",
    "#uncomment the nextlines only the first time to load imdb data and create dataframes\n",
    "%run -i ./code/sentiment_imdb_load_createdf.py\n",
    "df_trn = pd.read_csv(CLAS_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(CLAS_PATH/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Awesome blend of love and suspense. A top clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Look, I loved the PROPER Anchorman film, but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Set in World Depression Era Prague, this is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt; Praise is the only thing I can gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>There's a general rule to follow about Bogart ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0       2  Awesome blend of love and suspense. A top clas...\n",
       "1       0  Look, I loved the PROPER Anchorman film, but t...\n",
       "2       1  Set in World Depression Era Prague, this is th...\n",
       "3       2  <br /><br /> Praise is the only thing I can gi...\n",
       "4       2  There's a general rule to follow about Bogart ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg\\n', 'pos\\n', 'unsup\\n']\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFIER PATH\n",
    "#\n",
    "# Create Data Frames ... DONT RUN THIS UNLESS NEED TO RECREATE DataFrames and SAVE\n",
    "# create dataframes and save to file\n",
    "# Standardized format for NLP\n",
    "# datarames used later\n",
    "\n",
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':trn_labels}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':val_labels}, columns=col_names)\n",
    "\n",
    "display(df_trn.head())\n",
    "\n",
    "# save data frame\n",
    "# Classifier data ... no header by default\n",
    "# after removing unsupervised (unlabeled classes = 2) there will be 25 K positive and 25 K negative\n",
    "df_trn[df_trn['labels']!=2].to_csv(CLAS_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(CLAS_PATH/'test.csv', header=False, index=False)\n",
    "\n",
    "(CLAS_PATH/'classes.txt').open('w', encoding='utf-8').writelines(f'{o}\\n' for o in CLASSES)\n",
    "print((CLAS_PATH/'classes.txt').open().readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Language Model Data ...  train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000 10000\n"
     ]
    }
   ],
   "source": [
    "# LANGUAGE MODEL\n",
    "\n",
    "# convenient function for splitting training and test data set, 10% for test \n",
    "#  LM we create our own validation set ... use sklearn train_test_split ... we specify the proportion\n",
    "#  random split into train and validation\n",
    "#  concatenate classification and training together 100K all together ... split into 10% test, 90% training\n",
    "trn_texts,val_texts = sklearn.model_selection.train_test_split(\n",
    "    np.concatenate([trn_texts,val_texts]), test_size=0.1)\n",
    "\n",
    "print(len(trn_texts), len(val_texts))\n",
    "\n",
    "# for the language model there are no labels, so we use zeros\n",
    "# using these standard formats just makes things easier for repeating consistent dataframe and csv \n",
    "# this for other data sets\n",
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':[0]*len(trn_texts)}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':[0]*len(val_texts)}, columns=col_names)\n",
    "\n",
    "# \n",
    "df_trn.to_csv(LM_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(LM_PATH/'test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To save time, Skip these next few cells and go to \"np.load()\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Tokenize (text tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the data frame again (... we could start from here in the future, after preliminaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(LM_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(LM_PATH/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# https://forums.fast.ai/t/lesson-4-oserror-cant-find-model-en/11252/4\n",
    "# pip install SpaCy\n",
    "# python -m spacy download en\n",
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the result at the end [35:42]. Beginning of the stream token (xbos), beginning of field number 1 token (xfld 1), and tokenized text. You’ll see that the punctuation is on whole now a separate token.\n",
    "\n",
    "t_up: t_up mgm — MGM was originally capitalized. But the interesting thing is that normally people either lowercase everything or they leave the case as is. Now if you leave the case as is, then “SCREW YOU” and “screw you” are two totally different sets of tokens that have to be learnt from scratch. Or if you lowercase them all, then there is no difference at all. So how do you fix this so that you both get a semantic impact of “I’M SHOUTING NOW” but not have to learn the shouted version vs. the normal version. So the idea is to come up with a unique token to mean the next thing is all uppercase. Then we lowercase it, so now whatever used to be uppercase is lowercased, and then we can learn the semantic meaning of all uppercase.\n",
    "\n",
    "tk_rep: Similarly, if you have 29 ! in a row, we don’t learn a separate token for 29 exclamation marks — instead we put in a special token for “the next thing repeats lots of times” and then put the number 29 and an exclamation mark (i.e. tk_rep 29 !). So there are a few tricks like that. If you are interested in NLP, have a look at the tokenizer code for these little tricks that Jeremy added in because some of them are kind of fun.\n",
    "\n",
    "  ' '.join(tok_trn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n xbos xfld 1 i saw this movie at the dragon*con 2006 independent film festival . it was awarded 2 awards at that festival and rightfully so . this is probably the best short horror film i \\'ve ever seen . the simplicity of camera usage really works.the main character is brilliant . his acting is quite good and is believable . the 3 cameras in the room with tim russel make his insanity that much more believable . i love it . i have talked with mike and he says that they are in the process of making a feature film compassing the first three chapters together . i ca n\\'t wait . i will be first in line for that film . the effects of the \" mirror \" creatures are used so well . you do n\\'t see them for very long so it scares the pants off of you when you do . i recommend this film to anyone who wants to watch a good horror movie for once . best 32 minutes of spine tingling horror i \\'ve ever seen . thanks mike .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(tok_trn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save this and load back up later ... \n",
    "np.save(LM_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(LM_PATH/'tmp'/'tok_val.npy', tok_val )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing with doing things this way is we can now just np.save that and load it back up later [37:44]. We don’t have to recalculate all this stuff each time like we tend to have to do with torchtext or a lot of other libraries. Now that we got it tokenized, the next thing we need to do is to turn it into numbers which we call numericalizing it. The way we numericalize it is very simple.\n",
    "\n",
    "* We make a list list of all the words that appear in some order\n",
    "* Then we replace every word with its index into that list\n",
    "* The list of all the tokens, we call that the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Numericalized Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.load\n",
    "# tokenize -> numericalize it ... all the tokens we call the vocabularty\n",
    "tok_trn = np.load(LM_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(LM_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Counter class in Python is very handy for this. It basically gives us a list of unique items and their counts. Here are the 25 most common things in the vocabulary. Generally speaking, we don’t want every unique token in our vocabulary. If it doesn’t appear at least twice then might just be a spelling mistake or a word we can’t learn anything about it if it doesn’t appear that often. Also the stuff we are going to be learning about so far in this part gets a bit clunky once you’ve got a vocabulary bigger than 60,000. Time permitting, we may look at some work Jeremy has been doing recently on handling larger vocabularies, otherwise that might have to come in a future course. But actually for classification, doing more than about 60,000 words doesn’t seem to help anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1208449),\n",
       " ('.', 992545),\n",
       " (',', 986614),\n",
       " ('and', 587567),\n",
       " ('a', 583520),\n",
       " ('of', 525412),\n",
       " ('to', 484871),\n",
       " ('is', 393923),\n",
       " ('it', 341485),\n",
       " ('in', 337351),\n",
       " ('i', 307751),\n",
       " ('this', 270410),\n",
       " ('that', 261107),\n",
       " ('\"', 237920),\n",
       " (\"'s\", 222037),\n",
       " ('-', 188209),\n",
       " ('was', 180235),\n",
       " ('\\n\\n', 179009),\n",
       " ('as', 166145),\n",
       " ('with', 159253),\n",
       " ('for', 158601),\n",
       " ('movie', 157735),\n",
       " ('but', 150659),\n",
       " ('film', 144618),\n",
       " ('you', 123979)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  this is sorted by frequency\n",
    "freq = Counter(p for o in tok_trn for p in o)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocab is the unique set of all tokens in our dataset. The vocab provides us a way for us to simply replace each word in our datasets with a unique integer called an index. In a large corpus of data one might find some rare words which are only used a few times in the whole dataset. We discard such rare words and avoid trying to learn meaningful patterns out of them.\n",
    "\n",
    "Here we have set a minimum frequency of occurence to 2 times. It has been observed by NLP practicioners that a maximum vocab of 60k usually yields good results for classification tasks. So we set max_vocab to 60000.\n",
    "\n",
    "Note, time permitting we will discuss larger vocab sizes, but may not have time in this course. So we are going to limit our vocabulary to 60,000 words, things that appear at least twice [39:33]. Here is a simple way to do that. Use .most_common (Counter), pass in the max vocab size. That’ll sort it by the frequency and if it appears less often than a minimum frequency, then don’t bother with it at all.\n",
    "\n",
    "That gives us itos — that’s the same name that torchtext used and it means integer-to-string. This is just the list of unique tokens in the vocab. We’ll insert two more tokens — a vocab item for unknown (unk) and a vocab item for padding (pad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_unk_', '_pad_', 'the', '.', ',']\n"
     ]
    }
   ],
   "source": [
    "# must appear greater than min_freq ... words must appear at least 2x or don't bother\n",
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "# insert two more tokens ... padding and uknown\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "print(itos[0:5])\n",
    "# the index is the id ... of the word itos[id] = some word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a reverse mapping called stoi which is useful to lookup the index of a given token. stoi also has the same number of elements as itos. We use a high performance container called [collections.defaultdict](https://docs.python.org/2/library/collections.html#collections.defaultdict) to store our stoi mapping.\n",
    "\n",
    "We can then create the dictionary which goes in the opposite direction (string to integer)[40:19]. That won’t cover everything because we intentionally truncated it down to 60,000 words. If we come across something that is not in the dictionary, we want to replace it with zero for unknown so we can use defaultdict with a lambda function that always returns zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some items will not be in the dictonary (e.g., did not appar twice in the text) \n",
    "#  so use default dict and fill with 0 for such cases\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "print(stoi['_unk_'])\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numericalized Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(90000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NUMERICALIZED CORPUS\n",
    "# this is where the default dictionary comes in \n",
    "#  when trying to access stoi[i] there is a chance that o is not in the dictionary\n",
    "#  in that case the default dict will employ it's default factory, which in this case generates a 0\n",
    "# for every reveiw use stoi to replace string token with an integer token \n",
    "# this is the \"numericalized\" corpus\n",
    "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])\n",
    "\n",
    "print(type(trn_lm))\n",
    "trn_lm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our numericalized corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40 41 42 39 12 235 13 23 44 2 0 3368 1662 25 1331 3 10 18 8833 261 2474 44 14 1331 5 9383 51 3 13 9 263 2 138 364 200 25 12 159 143 129 3 2 5416 7 371 9080 83 58696 305 122 9 556 3 35 136 9 204 66 5 9 842 3 2 379 3992 11 2 655 21 1895 13095 113 35 4853 14 93 67 842 3 12 133 10 3 12 36 3515 21 1555 5 34 566 14 45 33 11 2 1648 7 251 6 820 25 0 2 105 299 8000 312 3 12 196 29 881 3 12 104 37 105 11 367 22 14 25 3 2 306 7 2 15 3006 15 2204 33 345 51 88 3 26 57 29 82 111 22 69 216 51 10 2702 2 3719 141 7 26 68 26 57 3 12 404 13 25 8 273 48 505 8 126 6 66 200 23 22 301 3 138 13558 249 7 7191 21684 200 12 159 143 129 3 1179 1555 3'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(str(o) for o in trn_lm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the nice thing is we can save that step as well. Each time we get to another step, we can save it. These are not very big files compared to what you are used with images. Text is generally pretty small. Very important to also save that vocabulary (itos). The list of numbers means nothing unless you know what each number refers to, and that’s what itos tells you. Save those three things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'trn_ids.npy', trn_lm)\n",
    "np.save(LM_PATH/'tmp'/'val_ids.npy', val_lm)\n",
    "pickle.dump(itos, open(LM_PATH/'tmp'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load them back up ... below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Pre trained language weights\n",
    "\n",
    "For reference, look at lesson10_alg_imdb_nlp_sentiment.ipynb for a working notebook\n",
    "\n",
    "We are now going to build an english language model for the IMDB corpus. We could start from scratch and try to learn the structure of the english language. But we use a technique called transfer learning to make this process easier. In transfer learning (a fairly recent idea for NLP) a pre-trained LM that has been trained on a large generic corpus(like wikipedia articles) can be used to transfer it's knowledge to a target LM and the weights can be fine-tuned.\n",
    "\n",
    "Our source LM is the wikitext103 LM created by Stephen Merity @ Salesforce research. [Link to dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\n",
    "The language model for wikitext103 (AWD LSTM) has been pre-trained and the weights can be downloaded here: [Link](http://files.fast.ai/models/wt103/). Our target LM is the IMDB LM.\n",
    "\n",
    "Here is kind of a new insight that’s not new at all which is that we’d like to pre-train something. We know from lesson 4 that if we pre-train our classifier by first creating a language model and then fine-tuning that as a classifier, that was helpful. It actually got us a new state-of-the-art result — we got the best IMDb classifier result that had been published by quite a bit. We are not going that far enough though, because IMDb movie reviews are not that different to any other English document; compared to how different they are to a random string or even to a Chinese document. So just like ImageNet allowed us to train things that recognize stuff that kind of looks like pictures, and we could use it on stuff that was nothing to do with ImageNet like satellite images. Why don’t we train a language model that’s good at English and then fine-tune it to be good at movie reviews.\n",
    "\n",
    "Our source LM is the wikitext103 LM created by Stephen Merity @ Salesforce research. Link to dataset The language model for wikitext103 (AWD LSTM) has been pre-trained and the weights can be downloaded here: Link. Our target LM is the IMDB LM.\n",
    "\n",
    "```\n",
    "   wget -nH -r -np http://files.fast.ai/models/wt103\n",
    "   \n",
    "   -r ... recursively grab entire directory\n",
    "   \n",
    "   make sure same embedding, hidden and number of layers that wiki text has\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go ahead and `torch.load` in those weights from the forward wikitext103 model. We don’t normally use torch.load, but that’s the PyTorch way of grabbing a file. It basically gives you a dictionary containing the name of the layer and a tensor/array of those weights.\n",
    "\n",
    "Now the problem is that wikitext language model was built with a certain vocabulary which was not the same as ours [47:14]. Our #40 is not the same as wikitext103 model’s #40. So we need to map one to the other. That’s very very simple because luckily Jeremy saved `itos` for the wikitext vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 90000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))\n",
    "vs=len(itos)\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PRE_PATH = PATH/'models'/'wt103'\n",
    "PRE_PATH = Path('data/models/wt103')\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'\n",
    "\n",
    "# Create the embeddings network sizing parameters\n",
    "#  make sure same embedding, hidden, and number of layers that wiki text has\n",
    "# otherwise can't load the weights in\n",
    "em_sz,nh,nl = 400,1150,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch load weights from the fwd_wt103 model\n",
    "# don't usually use PyTorch load, but works this time\n",
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the mean of the layer0 encoder weights. This can be used to assign weights to unknown tokens when we transfer to target IMDB LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of what each word is for wikitext103 model, and we can do the same defaultdict trick to map it in reverse. We’ll use -1 to mean that it is not in the wikitext dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_pad_', 'the', ',', '.', 'of', 'and', 'in', 'to', 'a']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos2 = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb'))\n",
    "stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})\n",
    "itos2[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we try to transfer the knowledge from wikitext to the IMDB LM, we match up the vocab words and their indexes. \n",
    "We use the defaultdict container once again, to assign mean weights to unknown IMDB tokens that do not exist in wikitext103.\n",
    "\n",
    "So now we can just say our new set of weights is just a whole bunch of zeros with vocab size by embedding size (i.e. we are going to create an embedding matrix) [47:57]. We then go through every one of the words in our IMDb vocabulary. We are going to look it up in stoi2 (string-to-integer for the wikitext103 vocabulary) and see if it’s a word there. If that is a word there, then we won’t get the -1. So r will be greater than or equal to zero, so in that case, we will just set that row of the embedding matrix to the weight which was stored inside the named element ‘0.encoder.weight’. You can look at this dictionary wgts and it’s pretty obvious what each name corresponds to. It looks very similar to the names that you gave it when you set up your module, so here are the encoder weights.\n",
    "\n",
    "\n",
    "If we don’t find it [49:02], we will use the row mean — in other words, here is the average embedding weight across all of the wikitext103. So we will end up with an embedding matrix for every word that’s in both our vocabulary for IMDb and the wikitext103 vocab, we will use the wikitext103 embedding matrix weights; for anything else, we will just use whatever was the average weight from the wikitext103 embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create an embeddijng matrix \"new_w\" all zeros, size is vocabulary size (vs) by embedding size (em_sz)\n",
    "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
    "for i,w in enumerate(itos): # go through all words in IMDb vocab\n",
    "    r = stoi2[w]  # look up in wiki vocab\n",
    "    # if r >= 0 then set the embedding wight from wiki text to enc_wgts[r] ... \n",
    "    # otherwise, see above row_m is average embedding weights\n",
    "    new_w[i] = enc_wgts[r] if r>=0 else row_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now overwrite the weights into the wgts dict.\n",
    "The decoder module, which we will explore in detail is also loaded with the same weights due to an idea called weight tying.\n",
    "\n",
    "* We will then replace the encoder weights with new_w turn into a tensor [49:35]. \n",
    "* We haven’t talked much about weight tying, but basically the decoder (the thing that turns the final prediction back into a word) uses exactly the same weights, so we pop it there as well. \n",
    "* Then there is a bit of weird thing with how we do embedding dropout that ends up with a whole separate copy of them for a reason that doesn’t matter much. So we popped the weights back where they need to go. \n",
    "\n",
    "So this becomes now a set of torch state which we can load in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replace encoder weights turned into a tensor\n",
    "wgts['0.encoder.weight'] = T(new_w)\n",
    "# weird thing about embedding dropout ... don't matter much don't pay attention to it\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "#  decoder the thing turns final predictions into wrd uses same weights so pop it thre as well \n",
    "wgts['1.decoder.weight'] = T(np.copy(new_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Crearte Language Model and Concatenate all docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25007908, 390748)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate all documents together into single list of tokens of length 24,998 million \n",
    "# ... continually trying to predict whats the next word after these, what's the next after these ... \n",
    "t = len(np.concatenate(trn_lm))\n",
    "t, t//64\n",
    "\n",
    "# out: (25007908, 390748)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our language model loader took in all of the documents concatenated together along with batch size and bptt [1:09:14]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wd=1e-7 \n",
    "#bptt=70  # runs out of memory after first learner .... \n",
    "bptt=70\n",
    "bs=52\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concatenate all documents together into single list of tokens of length 24,998 million ... language model\n",
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "# model data object\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the language model is:\n",
    "\n",
    "* RNN → A linear layer with dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout (1:20:36) \n",
    "\n",
    "What dropout you choose matters a lot .Through a lot of experimentation, Jeremy found a bunch of dropouts that tend to work pretty well for language models. But if you have less data for your language model, you’ll need more dropout. If you have more data, you can benefit from less dropout. You don’t want to regularize more than you have to. Rather than having to tune every one of these five things, Jeremy’s claim is they are already pretty good ratios to each other, so just tune this number (0.7 below), we just multiply it all by something. If you are overfitting, then you’ll need to increase the number, if you are underfitting, you’ll need to decrease this. Because other than that, these ratio seem pretty good.\n",
    "\n",
    "We setup the dropouts for the model - these values have been chosen after experimentation. If you need to update them for custom LMs, you can change the weighting factor (0.7 here) based on the amount of data you have. For more data, you can reduce dropout factor and for small datasets, you can reduce overfitting by choosing a higher dropout factor. *No other dropout value requires tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first tune the last embedding layer so that the missing tokens initialized with mean weights get tuned properly. So we freeze everything except the last layer.\n",
    "\n",
    "We also keep track of the *accuracy* metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Fit Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# grab the learner from the model data object\n",
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.model.load_state_dict(wgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We set learning rates and fit our IMDB LM. We first run one epoch to tune the \n",
    "# last layer which contains the embedding weights. This should help the missing tokens \n",
    "# in the wikitext103 learn better weights.\n",
    "\n",
    "lr=1e-3\n",
    "lrs = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a894410b0fb4a2d844666cb4cd918d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                       \n",
      "    0      4.665607   4.440533   0.258175  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([4.44053]), 0.2581753991250917]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as usual call learner.fit ... \n",
    "#   setup so the last layer is the embedding words, \n",
    "#   need tuning ... train single epoch\n",
    "learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1)\n",
    "\n",
    "# 4/17,2019\n",
    "# bs =52, bptt=70\n",
    "# Epoch ,,, 100% 1/1 [1:10:42<00:00, 4242.42s/it]\n",
    "# epoch      trn_loss   val_loss   accuracy                       \n",
    "#    0      4.665607   4.440533   0.258175 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we print out accuracy and keep track of how often we end up predicting the target word correctly. While this is a good metric to check, it is not part of our loss function as it can get quite bumpy. We only minimize cross-entropy loss in the LM.\n",
    "\n",
    "The exponent of the cross-entropy loss is called the perplexity of the LM. (low perplexity is better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.save('lm_last_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.load('lm_last_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2533324c94458f9ff5c0260c050bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                       \n",
      "    0      4.744665   4.596737   0.246392  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find(start_lr=lrs/10, end_lr=lrs*10, linear=True)\n",
    "# 4/17,2019\n",
    "# bs =52, bptt=70\n",
    "# epoch 100% 1/1 [1:20:39<00:00, 4839.82s/it]\n",
    "#epoch      trn_loss   val_loss   accuracy                       \n",
    "#    0      4.744665   4.596737   0.246392  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e8a0e0622243c08f6409ff22176dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                       \n",
      "    0      4.342637   4.163584   0.285316  \n",
      "  5%|▌         | 350/6869 [04:02<1:14:00,  1.47it/s, loss=4.34]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1      4.226193   4.085613   0.292141                       \n",
      "    2      4.139725   4.040766   0.297033                       \n",
      " 61%|██████▏   | 4215/6869 [47:34<30:16,  1.46it/s, loss=4.14]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3      4.089726   4.013811   0.299732                       \n",
      "    4      4.061208   3.993925   0.301871                       \n",
      "    5      4.031773   3.979702   0.303671                       \n",
      "  3%|▎         | 186/6869 [02:06<1:16:59,  1.45it/s, loss=4.04]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6      4.059679   3.96636    0.304913                       \n",
      " 66%|██████▋   | 4555/6869 [51:27<27:20,  1.41it/s, loss=4]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7      3.989331   3.958235   0.305902                       \n",
      " 54%|█████▎    | 3681/6869 [41:33<38:24,  1.38it/s, loss=3.99]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9      3.964807   3.942696   0.30779                        \n",
      " 35%|███▍      | 2391/6869 [27:05<52:19,  1.43it/s, loss=3.98]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 4446/6869 [50:23<26:01,  1.55it/s, loss=3.93]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 6667/6869 [1:15:22<02:20,  1.44it/s, loss=3.93]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    13     3.883847   3.922323   0.310715                       \n",
      " 18%|█▊        | 1233/6869 [13:58<1:02:54,  1.49it/s, loss=3.91]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start doing epochs for the full model ... \n",
    "# lesson 4 after 14 epochs had a 4.23 loss ... here after one epoch have 4.12 epoch loss\n",
    "learner.fit(lrs, 1, wds=wd, use_clr=(20,10), cycle_len=15)\n",
    "\n",
    "# bs 52, bptt=70 notebook (March 31, 2019)\n",
    "#epoch      trn_loss   val_loss   accuracy                       \n",
    "#    0      4.331119   4.16258    0.285376\n",
    "#    5      4.053623   3.978126   0.303586 \n",
    "#    8      3.968421   3.951115   0.30676  \n",
    "#    11     3.909159   3.93127    0.30937                        \n",
    "#    12     3.889581   3.926714   0.310039\n",
    "#    14     3.909791   3.915993   0.311308   \n",
    "\n",
    "#epoch      trn_loss   val_loss   accuracy \n",
    "# 0      4.338338   4.175916   0.284463\n",
    "# 2      4.174276   4.063725   0.295824   \n",
    "# 3      4.134645   4.040154   0.298624\n",
    "# 5      4.074611   4.007141   0.30222  \n",
    "# 7      4.052532   3.982075   0.304748\n",
    "# 9      3.990863   3.969266   0.30669 \n",
    "# 10     4.025941   3.95892    0.307883\n",
    "# 11     3.962463   3.955428   0.308491 \n",
    "# 12     3.951181   3.947853   0.309556\n",
    "# 13     3.92437    3.944853   0.309967   \n",
    "# 14     3.94222    3.939546   0.310581 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the trained model weights and separately save the encoder part of the LM model as well. This will serve as our backbone in the classification task model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.save('lm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.save_encoder('lm1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save_encoder [1:31:55]\n",
    "\n",
    "You’ll see there are two different versions of save. \n",
    "* save saves the whole model as per usual - LinearDecoder(n_tok, emb_sz, dropout, tie_encoder=enc) (which is the bit that actually makes it into a language model). - * We don’t care about that bit in the classifier, \n",
    "* save_encoder just saves that bit - just rnn_enc - this is what the classifier uses\n",
    "\n",
    "<img src=\"./pics/save_encoder.png\" style=\"height:200px;width:600px;\" >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Measuring LM Accuracy\n",
    "\n",
    "Measuring accuracy [1:21:45]\n",
    "One important idea which may seem minor but again it’s incredibly controversial is that we should measure accuracy when we look at a language model . Normally for language models, we look at a loss value which is just cross entropy loss but specifically we nearly always take e to the power of that which the NLP community calls “perplexity”. So perplexity is just e^(cross entropy). There is a lot of problems with comparing things based on cross entropy loss. \n",
    "\n",
    "Not sure if there’s time to go into it in detail now, but the basic problem is that it is like that thing we learned about focal loss. Cross entropy loss — if you are right, it wants you to be really confident that you are right. So it really penalizes a model that doesn’t say “I’m so sure this is wrong” and it’s wrong. Whereas accuracy doesn’t care at all about how confident you are — it cares about whether you are right. This is much more often the thing which you care about in real life. The accuracy is how often do we guess the next word correctly and it’s a much more stable number to keep track of. So that’s a simple little thing that Jeremy does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train for a while and we get down to a 3.9 cross entropy loss which is equivalent of ~49.40 perplexity (e^3.9) [1:23:14]. To give you a sense of what’s happening with language models, if you look at academic papers from about 18 months ago, you’ll see them talking about state-of-the-art perplexity of over a hundred. The rate at which our ability to understand language and measuring language model accuracy or perplexity is not a terrible proxy for understanding language. If I can guess what you are going to say next, I need to understand language well and the kind of things you might talk about pretty well. The perplexity number has just come down so much that it’s been amazing, and it will come down a lot more. NLP in the last 12–18 months, it really feels like 2011–2012 computer vision. We are starting to understand transfer learning and fine-tuning, and basic models are getting so much better. Everything you thought about what NLP can and can’t do is rapidly going out of date. There’s still lots of things NLP is not good at to be clear. Just like in 2012, there were lots of stuff computer vision wasn’t good at. But it’s changing incredibly rapidly and now is a very very good time to be getting very good at NLP or starting startups base on NLP because there is a whole bunch of stuff which computers would absolutely terrible at two years ago and now not quite good as people and then next year, they’ll be much better than people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is your ratio of paper reading vs. coding in a week [1:25:24]? Gosh, what do you think, Rachel? You see me. I mean, it’s more coding, right? “It’s a lot more coding. I feel like it also really varies from week to week” (Rachel). With that bounding box stuff, there were all these papers and no map through them, so I didn’t even know which one to read first and then I’d read the citations and didn’t understand any of them. So there was a few weeks of just kind of reading papers before I even know what to start coding. That’s unusual though. Anytime I start reading a paper, I’m always convinced that I’m not smart enough to understand it, always, regardless of the paper. And somehow eventually I do. But I try to spend as much time as I can coding.\n",
    "Nearly always after I’ve read a paper [1:26:34], even after I’ve read the bit that says this is the problem I’m trying to solve, I’ll stop there and try to implement something that I think might solve that problem. And then I’ll go back and read the paper, and I read little bits about these are how I solve these problem bits, and I’ll be like “oh that’s a good idea” and then I’ll try to implement those. That’s why for example, I didn’t actually implement SSD. My custom head is not the same as their head. It’s because I kind of read the gist of it and then I tried to create something as best as I could, then go back to the papers and try to see why. So by the time I got to the focal loss paper, Rachel will tell you, I was driving myself crazy with how come I can’t find small objects? How come it’s always predicting background? I read the focal loss paper and I was like “that’s why!!” It’s so much better when you deeply understand the problem they are trying to solve. I do find the vast majority of the time, by the time I read that bit of the paper which is solving a problem, I’m then like “yeah, but these three ideas I came up with, they didn’t try.” Then you suddenly realize that you’ve got new ideas. Or else, if you just implement the paper mindlessly, you tend not to have these insights about better ways to do it ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Is your dropout rate the same through the training or do you adjust it and weights accordingly [1:26:27]? Varying dropout is really interesting and there are some recent papers that suggest gradually changing dropout [1:28:09]. It was either good idea to gradually make it smaller or gradually make it bigger, I’m not sure which. Maybe one of us can try and find it during the week. I haven’t seen it widely used. I tried it a little bit with the most recent paper I wrote and I had some good results. I think I was gradually make it smaller, but I can’t remember.\n",
    "\n",
    "Question: Am I correct in thinking that this language model is build on word embeddings? Would it be valuable to try this with phrase or sentence embeddings? I ask this because I saw from Google the other day, universal sentence encoder [1:28:45]. This is much better than that. This is not just an embedding of a sentence, this is an entire model. An embedding by definition is like a fixed thing. A sentence or a phase embedding is always a model that creates that. We’ve got a model that’s trying to understand language. It’s not just as phrase or as sentence — it’s a document in the end, and it’s not just an embedding that we are training through the whole thing. This has been a huge problem with NLP for years now is this attachment they have to embeddings. Even the paper that the community has been most excited about recently from AI2 (Allen Institute for Artificial Intelligence) called ELMo — they found much better results across lots of models, but again it was an embedding. They took a fixed model and created a fixed set of numbers which they then fed into a model. But in computer vision, we’ve known for years that that approach of having fixed set of features, they’re called hyper columns in computer vision, people stopped using them like 3 or 4 years ago because fine-tuning the entire model works much better. For those of you that have spent quite a lot of time with NLP and not much time with computer vision, you’re going to have to start re-learning. All that stuff you have been told about this idea that there are these things called embeddings and that you learn them ahead of time and then you apply these fixed things whether it be word level or phrase level or whatever level — don’t do that. You want to actually create a pre-trained model and fine-tune it end-to-end, then you’ll see some specific results.\n",
    "\n",
    "Question: For using accuracy instead of perplexity as a metric for the model, could we work that into the loss function rather than just use it as a metric [1:31:21]? No, you never want to do that whether it be computer vision or NLP or whatever. It’s too bumpy. So cross entropy is fine as a loss function. And I’m not saying instead of, I use it in addition to. I think it’s good to look at the accuracy and to look at the cross entropy. But for your loss function, you need something nice and smoothy. Accuracy doesn’t work very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
