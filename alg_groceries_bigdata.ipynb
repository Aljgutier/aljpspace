{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groceries - Big DataÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corporacion Favorita Grocery Sales Forecasting\n",
    "\n",
    "Forecast, dependent variable, how many units of what kind of product were sold in each store, for each type of producrt, on each day were sold, for a two week period. For each date have meta data, like oil prices. \n",
    "\n",
    "Key things to understand are the \n",
    " - dependent variable\n",
    " - independent variable\n",
    " - and time frame\n",
    "\n",
    "This is like a star schema data warehousing style data set. Have a central data set of transactions, items sold, by id. Fron there can join all kinds of meta, data from different tables. Like info on the stores.\n",
    "Sometimes see snowflake schema. there may be information joined to the transactions talbe that tells you about the transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holidays_events.csv.7z\tsample_submission.csv.7z  test.csv.7z\r\n",
      "items.csv.7z\t\tstores.csv.7z\t\t  train.csv\r\n",
      "oil.csv.7z\t\ttest.csv\t\t  train.csv.7z\r\n"
     ]
    }
   ],
   "source": [
    "# start as before\n",
    "\n",
    "PATH = \"./data/groceries/\"\n",
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over 100 million rows\n",
    "# create dictionary of each column\n",
    "# this way PD does not have to read the entire csv to figure out the \n",
    "#\n",
    "# why ints\n",
    "# use smallest number of bits to represent the column\n",
    "types ={'id': 'int64',\n",
    "       'item_nbr': 'int32',\n",
    "       'store_nbr': 'int8',\n",
    "       'unit_sales':'float32',\n",
    "       'onpromotion':'object'}\n",
    "# on promotion is a boolean has missing values and we will have to deal with it \n",
    "# before turning it into a boolean. So, next we fill in the missing values with false.\n",
    "# Objects generally read in as strings. Below will replace the strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 7.02 s, total: 1min 46s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "# It takes 1min 48s to read in the data\n",
    "\n",
    "%time df_all = pd.read_csv(f'{PATH}train.csv', parse_dates = ['date'], dtype=types, infer_datetime_format = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowIOError",
     "evalue": "Failed to open local file: tmp/raw_groceries , error: Success",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowIOError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_feather\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \"\"\"\n\u001b[1;32m   1891\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeather_format\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_feather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1892\u001b[0;31m         \u001b[0mto_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m     def to_parquet(self, fname, engine='auto', compression='snappy',\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36mto_feather\u001b[0;34m(df, path)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feather must have string column names\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mfeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pyarrow/feather.py\u001b[0m in \u001b[0;36mwrite_feather\u001b[0;34m(df, dest)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mLocal\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatherWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pyarrow/feather.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dest)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeatherWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pyarrow/feather.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.FeatherWriter.open (/arrow/python/build/temp.linux-x86_64-3.6/lib.cxx:73279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.get_writer (/arrow/python/build/temp.linux-x86_64-3.6/lib.cxx:58853)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.OSFile.__cinit__ (/arrow/python/build/temp.linux-x86_64-3.6/lib.cxx:55283)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.OSFile._open_writeable (/arrow/python/build/temp.linux-x86_64-3.6/lib.cxx:55533)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status (/arrow/python/build/temp.linux-x86_64-3.6/lib.cxx:8345)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowIOError\u001b[0m: Failed to open local file: tmp/raw_groceries , error: Success"
     ]
    }
   ],
   "source": [
    "# exploratory data analysis indicates that missing corresponds to False\n",
    "# replace missing with false\n",
    "df_all.onpromotion.fillna(False, inplace = True)\n",
    "# map trasform \"True and False\" strings to booleans\n",
    "df_all.onpromotion = df_all.onpromotion.map({'False' : False, 'True' : True})\n",
    "# convert to boolean types\n",
    "df_all.onpromotion = df_all.onpromotion.astype(bool)\n",
    "\n",
    "%time df_all.to_feather('tmp/raw_groceries')\n",
    "\n",
    "# this file, 125 million rows, takes something like 2.5 GB of memory\n",
    "# save to feather format in under 5 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 125.5 million rows\n",
    "# Because Pandas is pretty fast can summarize all 125 million rows, 20 cols, in\n",
    "# about 23 s\n",
    "%time df_all.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When people say Python is slow, they probably don't know how to use it properly. Python is slow if you don't use it correctly. 125 million CSV records in < 2 min. Actually, its going to C-Code. Python itself isn't very fast. Almost evrything we want to do in Data Science is really run in Cython, Pandas, heavily optimized. If we wrote our own CSV reader in Python it would take 1000's of time slower.\n",
    "\n",
    "**Need to tell it two things**\n",
    "- dates\n",
    "- datatypes\n",
    "\n",
    "**Why int64,32, 8?**\n",
    "Use the smallest No. of bits.  Purpose here is to avoid running out of RAM. However when working with large datasets, slow piece is reading and writing to RAM. As a rule of thumb smaller data sets run faster especially in SIMD (single instruction multiple data vectorized code) can pack more numbes into a single number to run at once.\n",
    "\n",
    "**Start with sample**\n",
    "Tip when start, don't usually read in the whole thing. Use unix shuf to read a random sample. Search forum for shuf to get randome sample at the command promp. Good way to get started and do some exploring, understand data types ... generally do work on sample to understand before moving on.\n",
    "\n",
    "**models on large data sets**\n",
    "We'll talk about "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand dates\n",
    "First thing look at dates\n",
    "\n",
    "Dates will be very important\n",
    "\n",
    "Kaggle make sure dates don't overlap between train and test\n",
    "Train last date aug 15, 2017\n",
    "Test set starts one day later, Aug 16, 2017\n",
    "Have 4 years of data and trying to predict the next 4 weeks. \n",
    "\n",
    "How to sample? Get from the bottom, most recent data for prediction. Hedge that it will be close to most recent. There will be some useful information from 4 years ago, so don't want to through that information away. But, perhaps start with easy models staring with recent dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at bottom of the data set\n",
    "#   store number, item no. , onpromotion (on sale)\n",
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Metric Log RMSE (also review lesson 1 for reasoning)\n",
    "Take the log ... predict something accoerding to ratios ... so log .. competition details will ... there are negative sales that should be considered returns and make them 0.\n",
    "Take the log plus 1, as specified in the Kaggle competition, because log zero "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all= pd.read_feather('tmp/raw_groceries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.unit_sales = np.log1p(np.clip(df_all.unit_sales,0,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add datepart as usual\n",
    "%time add_datepart(df_all,'date')\n",
    "# takes 1min 53 s ... run through on a sample first so takes 10s \n",
    "# ... Jeremy's rule of thumb sample so everything takes less than 10 s for exploration\n",
    "# to make sure evrything looks reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much the code looks almost identical as the bulldozers competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vals(a,n): return a[:n].copy(), a[n:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out the validation set into 12,000 rows \n",
    "# training set will contain everything else\n",
    "# most recent rows will be our validation set. \n",
    "# Generally speaking top half of Kaggle is pretty good. \n",
    "# ... Off the block in top 25% ... with no thinking in top 25%\n",
    "\n",
    "\n",
    "n_valid = len(df_test)\n",
    "n_trn = len(df)-n_valid\n",
    "\n",
    "train, valid = split_vals(df_all,n_trn)\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Variable names are a bit messed up\n",
    "In Lesson1 Jeremy defines df_raw = pd.read ... in this notebook df_all=pd.read\n",
    "Seems to mix up variables ... will need to sort all this out to get it to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data types are already numeric so dont need to do this\n",
    "#  turns string columns to pandas category class\n",
    "#train_cats(raw_train) \n",
    "#   apply same codes from training set to validation set\n",
    "#apply_cats(faw_valid, raw_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is key ... have 120 mil records\n",
    "# don't want a tree that big or long ... who knows how long it will take\n",
    "# start with 10K or 100K to see how long it takes, make sure it works\n",
    "# found that setting it to 1 million, m.fit it runs in less than 1 minute\n",
    "\n",
    "set_rf_samples(1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another key change the input data to an array of floats, why?\n",
    "#  internally, RF code they do this, doing it once myself save 1:37 sec\n",
    "# if you run the code and it takes a long time then use prun to understand what is \n",
    "# taking so long. In this example m.fit took 2.5 minutes, so investigated\n",
    "# and then pulled this line out\n",
    "%time x = np.array(trn, dtype=np.float32)\n",
    "%prun m.fit(x, y)\n",
    "\n",
    "# profiler will tell you how much time each line of code takes\n",
    "#  the x = np.array line was taking most of the time\n",
    "# software engineers appriciate this\n",
    "# data scientist often under appreciate it\n",
    "# try running prun and see if you can interpret and use profile outputs\n",
    "\n",
    "\n",
    "# oob score ... noticed in profile cannot use oob score \n",
    "# will try and use other 124 million rows to calculate oob\n",
    "# will take forever\n",
    "# so will need a proper validation set\n",
    "# DONT USE OOB on LARGE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=20, min_samples_leaf=100, max_features=0.5,\n",
    "                          n_jobs=-8, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long it takes to build the random forest?\n",
    "#   It is by No. of Estimators x Sampel Size\n",
    "#   not by the size of the data set\n",
    "\n",
    "# n_jobs\n",
    "#    the number of cores it will use, before we set it to -1\n",
    "#    computer had 60 cores, but spinning up jobs was taking too long\n",
    "#    -1 use all cores, like on your PC\n",
    "#\n",
    "# \n",
    "m = RandomForestRegressor(n_estimators=20, min_samples_leaf=100, max_features=0.5,\n",
    "                          n_jobs=-8, oob_score=True)\n",
    "%time m.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_socre(m)\n",
    "# gets a 0.76588 Log RMSE error\n",
    "# try fiddling out to min\n",
    "#   samples from 100 to 10 ... takes a LRMSE from 0.76 to 0.71\n",
    "#   down to 3 ... gets down to 0.70\n",
    "# this is a reasonable RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However 0.71 isn't so great on leaderboard\n",
    "\n",
    "Look at the columns that are predicting with\n",
    "- date, store, item no, on promoation, etc ... \n",
    "\n",
    "So, most of the insight, how much do you expect sell, will be wrapped up on where is that store, what category of item, and the day of the weeil\n",
    "\n",
    "A RF can only create binary splits, which store represents Gasoline, which store in center of city, etc. Its ability to understand whats going on is somewhat limited.\n",
    "\n",
    "Will need to use 4 years of data. There is a Kaggle competition. Take the last two weeks average sales by store, item, onpromotion, and take mean. You come out at about 30th.\n",
    "\n",
    "So, your job then is how do you start with that model and make it a little bit better. Kaggle many peopls started from this Kernal and started improving on it. \n",
    "\n",
    "Create a scatter plot Mean model on one axis Vs. new model ... should form a line, if not probably screwed something up.\n",
    "\n",
    "Pull in data from other soruces, like weather data ... this kind of thing is done very often ... weather is meta-data about a date. Most competitions have a rule that you can use external data, but have to post and it should be publicly available. Outside of Kaggle should always be looking for other data.\n",
    "\n",
    "Equador's largest grocery chain. Look for Equadaor holidays ... This information is provided in this case. \n",
    "\n",
    "Create lots of new columsn ...\n",
    "- avg no sales in holidays, \n",
    "- avg % change form Jan to Feb so on an so forth\n",
    "\n",
    "\n",
    "Also, look at similar competitions, \n",
    "- like Roseman (Germany)\n",
    "\n",
    "Person that won, created lots of columns based on whats useful for making predictions\n",
    "\n",
    "Third place team did almost no feature engineering \n",
    "\n",
    "\n",
    "**Tune Validation Set**\n",
    "- if you don't have a good validation set its hard almost impossible to create a good model\n",
    "- next month sales, are they good at predicting next month\n",
    "- need a validation set that is reliable for telling you that model will be good when put it into production\n",
    "- You should usually onl use Test set at tend, but can use it to calibrate the validation set\n",
    "- submit 4 models to Kaggle x axis is score from Kaggle on Y axis is validation set score to see if the validation set is any good. If the validation set is good then x,y should be on straight line as close to y = x as possible. If not, then your validation set is not good. Validation set will predict leader board score set well. \n",
    "\n",
    "\n",
    "New column examples\n",
    "- Date range of test set ... 14 days ... test set is 16 days ... test set begins after pay day and ends on pay day. one of the bits of meta-data they told us ... draw time-series and make sure you have some number of spikes in your test set ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grocery store notebook not in Github, but after competition \n",
    "### finsihed it will be on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
